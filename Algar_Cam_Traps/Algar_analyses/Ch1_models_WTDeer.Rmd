---
title: "Ch1_models_WTDeer"
author: "Erin Tattersall"
date: "May 11, 2018"
output: word_document
---

  Based on model selection comparison of underlying distributions and zero-inflation, I chose an nbinom1 distribution for WTDeer data, with zero-inflation and ActiveDays in the ZI model (see Ch1_WTDeer_modelDistribution.Rmd).  
  I previously had decided to include ActiveDays in the ZI model. However, to retain the same amount of data in each model, I need to omit rows with NAs. NA rows are usually those in which cameras were inactive. Therefore, in the final dataset used in modelling, ActiveDays should have a greater effect on the count data, not the zero mass, so it should be included in the conditional model.
Here I will: 
1. Double check random structure using all covariates
2. Build models assessing Treatment effect, including other combinations of covariates to account for additional noise and compare their effect to Treatment 
4. Perform model selection with AIC  
5. Calculate evidence ratios (AICwt of Best Model/ AICwt of other models)  
6. Checking residuals of Top Model
  
Previous scale analysis showed lowland habitat at 2000m and linear density measured at 750m best explained WTDeer detections


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(glmmTMB)
library(bbmle) #AICtab function
library(ggplot2)
library(lmtest)
library(reshape)
library(dplyr)
library(knitr)
library(MuMIn) #streamlining model selection

```
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
#Load detection data
det <- read.csv("Seismic_nov2015-apr2018.csv")

#Load lowland data
low <- read.csv("newAVIE_lowland8buffersizes.csv")

#Combine data
det$low250 <- low$low250[match(det$Site, low$CamStation)]
det$low500 <- low$low500[match(det$Site, low$CamStation)]
det$low750 <- low$low750[match(det$Site, low$CamStation)]
det$low1000 <- low$low1000[match(det$Site, low$CamStation)]
det$low1250 <- low$low1250[match(det$Site, low$CamStation)]
det$low1500 <- low$low1500[match(det$Site, low$CamStation)]
det$low1750 <- low$low1750[match(det$Site, low$CamStation)]
det$low2000 <- low$low2000[match(det$Site, low$CamStation)]

#Load linedensity data
LineDens <- read.csv("AlgarStationsLD_Lines.csv")

# Combine datasets
det$LD250 <- LineDens$X250m[match(det$Site, LineDens$CamStation)]
det$LD500 <- LineDens$X500m[match(det$Site, LineDens$CamStation)]
det$LD750 <- LineDens$X750m[match(det$Site, LineDens$CamStation)]
det$LD1000 <- LineDens$X1000m[match(det$Site, LineDens$CamStation)]
det$LD1250 <- LineDens$X1250m[match(det$Site, LineDens$CamStation)]
det$LD1500 <- LineDens$X1500m[match(det$Site, LineDens$CamStation)]
det$LD1750 <- LineDens$X1750m[match(det$Site, LineDens$CamStation)]
det$LD2000 <- LineDens$X2000m[match(det$Site, LineDens$CamStation)]


#Load line width and veg height
sp <- read.csv("Spatial_covariates.csv")

det$VegHt <- sp$VegHt[match(det$Site, sp$Site)]
det$LineWidth <- sp$LineWidth[match(det$Site, sp$Site)]


### Centring and standardizing covariates
## All continuous input variables need to be centred and standardized ((value - mean)/2SD; Gelman, 2008)
covscale <- function(covariate){
  centre <- (covariate - mean(covariate, na.rm = TRUE)) # where covariate is a vector of numeric input values for one covariate
  standardize <- centre/(2*sd(covariate, na.rm = TRUE)) # Divide centred value by 2 SD
}

summary(det$ActiveDays) #mean 18
sd(det$ActiveDays)
det$ActiveDays_sc <- covscale(det$ActiveDays)
summary(det$ActiveDays_sc)
sd(det$ActiveDays_sc)
det$D2W_sc <- covscale(det$Dist2Water_km) #mean 2.07
summary(det$Dist2Water_km) #mean 2.07
sd(det$Dist2Water_km) #1.76
summary(det$D2W_sc) #mean 0
sd(det$D2W_sc) #SD

det$pSnow_sc <- covscale(det$pSnow)
summary(det$pSnow_sc) #NAs, probably because of NAs in pSnow --> added na.rm = TRUE to function
det$pSnow_sc <- covscale(det$pSnow)
summary(det$pSnow_sc)
sd(det$pSnow_sc, na.rm = TRUE)
det$low250_sc <- covscale(det$low250)
det$low500_sc <- covscale(det$low500)
det$low750_sc <- covscale(det$low750)
det$low1000_sc <- covscale(det$low1000)
det$low1250_sc <- covscale(det$low1250)
det$low1500_sc <- covscale(det$low1500)
det$low1750_sc <- covscale(det$low1750)
det$low2000_sc <- covscale(det$low2000)
det$LD250_sc <- covscale(det$LD250)
det$LD500_sc <- covscale(det$LD500)
det$LD750_sc <- covscale(det$LD750)
det$LD1000_sc <- covscale(det$LD1000)
det$LD1250_sc <- covscale(det$LD1250)
det$LD1500_sc <- covscale(det$LD1500)
det$LD1750_sc <- covscale(det$LD1750)
det$LD2000_sc <- covscale(det$LD2000)
det$LineWidth_sc <- covscale(det$LineWidth)
det$VegHt_sc <- covscale(det$VegHt)

summary(det[ , 36:56]) #Centred means of 0

write.csv(det, "Seismic_nov2015-apr2018.csv")

# Omit NA rows
det <- na.omit(det)
```
### 1. Random structure and Active Days 
  Random structure was previously assessed, but here I will confirm using all model covariates. Also comparing random intercepts vs random slope 

```{r, echo=FALSE, message=FALSE}
r0 <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc, data = det, zi=~1,family = nbinom1)
rSite <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc + (1|Site), data = det, zi=~1,  family = nbinom1) 
rMonth <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc + (1|Month), data = det, zi=~1, family = nbinom1)
r2 <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc + (1|Site) + (1|Month), data = det, zi=~1, family = nbinom1)
rSiteS <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc + (Treatment|Site), data = det,zi=~1, family = nbinom1) 
rMonthS <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc +  (Treatment|Month), data = det, zi=~1, family = nbinom1)
r2S <- glmmTMB(WTDeer~ LineWidth_sc + LD750_sc + VegHt_sc + low2000_sc + Treatment + pSnow_sc + ActiveDays_sc + (Treatment|Site) + (Treatment|Month), data = det, zi=~1, family = nbinom1)
ICtab(r0, rSite, rMonth, r2, type= "AIC", weights = TRUE, delta = TRUE, logLik = TRUE, sort=TRUE)
```  
  Random slope models fail to converge, so exclude. Continue modelling with 2 random effects. ActiveDays in conditional model had slightly less model weight, so continue modelling ActiveDays in ZI only.
## Model Set  
 (note that numbered models from dredge do not correspond with numbers in table; I have listed models in order of increasing complexity, dredge did not)
 Also: ActiveDays is also fixed in all models (including NULL)

Model Name  | Covariates
----------- | -------------------
L0          | 1
L1          | Treatment
L2          | Treatment + low2000
L3          | Treatment + pSnow
L4          | Treatment + LineWidth 
L5          | Treatment + VegHt
L6          | Treatment + LD750
L7          | Treatment + low2000 + pSnow
L8          | Treatment + low2000 + LineWidth
L9          | Treatment + low2000 + VegHt
L10         | Treatment + low2000 + LD750
L11         | Treatment + pSnow + LineWidth
L12         | Treatment + pSnow + VegHt
L13         | Treatment + pSnow + LD750
L14         | Treatment + LineWidth + VegHt
L15         | Treatment + LineWidth + LD750
L16         | Treatment + VegHt + LD750
L17         | Treatment + low2000 + pSnow + LineWidth
L18         | Treatment + low2000 + pSnow + VegHt
L19         | Treatment + low2000 + pSnow + LD750
L20         | Treatment + low2000 + LineWidth + VegHt
L21         | Treatment + low2000 + LineWidth + LD750
L22         | Treatment + low2000 + VegHt + LD750
L23         | Treatment + pSnow + LineWidth + VegHt
L24         | Treatment + pSnow + LineWidth + LD750
L24         | Treatment + pSnow + VegHt + LD750
L25         | Treatment + LineWidth + VegHt + LD750
L26         | Treatment + low2000 + pSnow + LineWidth + VegHt
L27         | Treatment + low2000 + pSnow + LineWidth + LD750
L28         | Treatment + pSnow + LineWidth + VegHt + LD750
L29         | Treatment + low2000 + LineWidth + vegHt + LD750
L30         | Treatment + low2000 + pSnow + VegHt + LD750
L31         | Treatment + low2000 + pSnow + LineWidth + VegHt + LD750

```{r, echo=FALSE, message=FALSE, results='hide'}
# dredge function from MuMin generatesand evaluates model sets
global.model <- glmmTMB(WTDeer~  Treatment + low2000_sc + pSnow_sc + LineWidth_sc + LD750_sc + VegHt_sc + ActiveDays_sc + (1|Site) + (1|Month), data = det, zi=~1, family = nbinom1)

#List of all possible models including Treatment and some combination of other covariates. Runs models and returns a model selection data frame
Treat.models <- dredge(global.model = global.model, beta = "none", evaluate = TRUE, rank = "AIC", fixed = ~cond(Treatment) + cond(ActiveDays_sc), trace = TRUE) # Does not include null model
#Lists model objects
Models <- get.models(Treat.models, subset = TRUE)

## Add NULL model to list
NULLmod <- glmmTMB(WTDeer~ ActiveDays_sc + (1|Site) + (1|Month), data = det, zi=~1, family = nbinom1)
Models[["Nullmod"]] <- NULLmod

names(Models)
```
```{r,echo=FALSE}

WTDeerAIC <- ICtab(Models, mnames = names(Models), type= "AIC", weights = TRUE, delta = TRUE, logLik = TRUE, sort=TRUE)
WTDeerAIC
``` 
```{r, echo=FALSE, results='hide'}
summary(Models$`6`)

## Compare estimates to those in model with unstandardized covariates
unstd.mod <- glmmTMB(WTDeer~ LD750 + low2000 + pSnow + VegHt + Treatment + (1|Site) + (1|Month), data = det, zi=~ActiveDays_sc, family = nbinom1)
summary(unstd.mod) ### Treatment coefficients are the same but continuous covariate coefficients are not. Significance is same
```
  Five models within 2 dAIC points of each other, with model weights between 7 - 19%.
    
  
## Evidence Ratios and Cumulative model weight (calculating confidence intervals)
  
  Calculating evidence ratios (AIC wt of best model/AIC weight of others) gives:
  
```{r,echo=FALSE, results='hide'}
EvR <- function(AICwt.high, AICwt.low){
  EvR <- AICwt.high/AICwt.low
  print(EvR)
}
EvR(WTDeerAIC$weight[1], WTDeerAIC$weight[2])
WTDeerWt <- WTDeerAIC$weight
WTDeerER <- vector(length=32)
for(i in 2:33){
  WTDeerER[i-1] <- EvR(WTDeerWt[1], WTDeerWt[i])
}
```
```{r,echo=FALSE}
WTDeerER <- append("", WTDeerER)
ER <- as.data.frame(names(Models)) ## As dredge orders models based on dAIC scores, I call names directly
colnames(ER) <- "ModelNames"
ER$dLogLikelihood <- WTDeerAIC$dLogLik
ER$dAIC <- WTDeerAIC$dAIC
ER$Modelweight <- WTDeerAIC$weight
ER$CumulativeWeight <- rep(NA,33)
ER$CumulativeWeight[1] <- ER$Modelweight[1]
for (i in 2:length(ER$Modelweight)){
  ER$CumulativeWeight[i] <- ER$Modelweight[i] + ER$CumulativeWeight[i-1]
}
ER$EvidenceRatio <- WTDeerER

ER
```
 Examining summaries for top 4 models (2dAIC)  
```{r, echo=FALSE, results='hide'}
fixef(Models$`6`)
fixef(Models$`22`)
fixef(Models$`14`)
fixef(Models$`30`)
fixef(Models$`8`)
```  
In addtion to Treatment and ActiveDays, all 5 models contain LD and lowland. 2 contain pSnow and/or VegHt, and 1 contains LineWidth

### Pretending variables
  Comparing deviance of top models - if covariate does not add much, resdiual deviance will be similar across models
  
 Model                                       | Est. + SE of addtional variables             | Residual Deviance
---------------------------------------------|----------------------------------------------|---------------------
Treat + low + LD + ActiveDays                |                                              | 1398.2
Treat + low + LD + VegHt + ActiveDays        |  VegHt 0.49 +/- 0.40                         | 1396.7
Treat + low + LD + pSnow + ActiveDays        | Snow -0.46 +/- 0.38                          | 1396.8
Treat + low + LD + pSnow + VegHt + ActiveDays| Snow same VegHt -0.49 +/- 0.38               | 1395.4
Treat + low + LD + LineWidth + ActiveDays    | LineWidth -0.06 +/- 0.37                     | 1398.1

  Parameter estimates and deviance are similar, indicating all models are roughly equivalent to one another.

```{r, echo=FALSE, results='hide'}
summary(Models$`6`)
summary(Models$`22`)
summary(Models$`14`)
summary(Models$`30`)
summary(Models$`8`)
```

### Model averaging
  Multiple models are within 2dAIC scores of  each other, suggesting that they all explain the data equally well. As my goal is to compare Treatment effects to the effects of other covariates, I do not just want the estimates given in the top model, but rather the best possible estimates for many covariates. I will therefore model average to obtain a weighted average estimate (effect size) of covariates included in models that are within 2 dAIC of one another or within 95% confidence intervals, whichever is more conservative.
```{r, echo=FALSE}
#List of top models
WTDtop <- Models[1:5]
WTD.averaged <- model.avg(WTDtop)
summary(WTD.averaged) ## Look at full model --> parameters averaged over all models, with the coefficient set to 0 if the parameter is not present
Est.full <- WTD.averaged$coefficients[1,] #Estimates for the full average
CI95.full <- confint(WTD.averaged)
WTDEffects.CI <- as.data.frame(c("Intercept", "LineDens", "Lowland", "ActiveDays", "HumanUse", "NatRegen", "SPP", "ziIntercept", "VegHt", "pSnow", "LineWidth")) #Reorder according to order of averaged coefs
colnames(WTDEffects.CI) <- "Predictor"
WTDEffects.CI$Estimate <- Est.full
WTDEffects.CI$CIlow <- CI95.full[, 1]
WTDEffects.CI$CI.high <- CI95.full[, 2]
```
### Predictor Effect Sizes
```{r, echo=FALSE}
library(ggplot2)
ggplot(data = WTDEffects.CI, aes( x = Predictor, y = Estimate)) + geom_point() + geom_errorbar(aes(ymin=CIlow, ymax = CI.high))+ geom_hline(yintercept = 0) + scale_x_discrete(limits=c("NatRegen", "SPP", "HumanUse", "Lowland", "pSnow", "LineDens", "LineWidth", "VegHt"))+theme_classic() + theme(axis.text.x = element_text(angle = 45, hjust = 1, colour = "black", size = 12)) + theme(axis.title.x = element_text(angle = 0, colour = "black", size = 14)) + theme(axis.title.y = element_text(angle = 90, colour = "black", size = 14)) + theme(strip.text = element_text(colour = "black", size = 14)) + scale_y_continuous(limits = c(-3, 3))
```

## Exploring Interactions
  Interaction coefficients describe how much the slope of the continuous variable changes at one level of the categorical relative to the reference level
  Use top model, with Treatment and lowland interacting
```{r, echo=FALSE}
VTint <- glmmTMB(WTDeer~low2000_sc + ActiveDays_sc + Treatment*LD750_sc + (1 | Site) + (1 | Month), zi=~1, data=det, family=nbinom1)
summary(VTint)

VTint <- glmmTMB(WTDeer~LD750_sc + ActiveDays_sc + Treatment*low2000_sc + (1 | Site) + (1 | Month), zi=~1, data=det, family=nbinom1)
summary(VTint)



```
  Interpreted as SPP decreasing the main increasing effect of LineDens on detections. Will not include as according to the coplot this effect may be driven by one control site only (high linear density and high number of detections). Also, I did not include this interaction a priori but rather after examining effects of Treatment and LineDens separately.
  Treatment*Lowland: Treatment and lowland habitat have significant main effects, but not significant interactions. This means that relative to control lines, other treatments to do not significantly change the negative influence of lowland habitat